{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split \n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score, accuracy_score\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import pylab as pl\n",
    "from joblib import dump, load\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import image_lib as imlib\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RFclassification(df, getResult, crossval, testSize, pretrainedModel):\n",
    "    # Assigning data\n",
    "    X = df.drop(['label'], axis=1)   \n",
    "    y = df['label'] \n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    X_norm = scaler.fit_transform(X)\n",
    "    \n",
    "    # Splitting the data in to training and test data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_norm, y, test_size = testSize, random_state=10)\n",
    "    print('[UPDATE] Data has been loaded successfully!')\n",
    "    \n",
    "    if pretrainedModel == 'yes':\n",
    "        print('[UPDATE] Using pretrained model!')\n",
    "        RFclassifier = load('PIPE4_RF.joblib')\n",
    "        print('[UPDATE] Pretrained model loaded!')\n",
    "    \n",
    "    else:\n",
    "        # Identification of hyperparameters\n",
    "        #param_grid = {\n",
    "        #'bootstrap': [True],\n",
    "        #'max_depth': [2, 4, 8, 12, 20],\n",
    "        #'max_features': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11],\n",
    "        #'min_samples_leaf': [4, 5, 6],\n",
    "        #'min_samples_split': [2, 4, 8, 12],\n",
    "        #'n_estimators': [2, 4, 6, 12, 24, 48]\n",
    "        #}\n",
    "        \n",
    "        # The parameters used\n",
    "        param_grid = {\n",
    "        'bootstrap': [True],\n",
    "        'max_depth': [4],\n",
    "        'max_features': [3],\n",
    "        'min_samples_leaf': [5],\n",
    "        'min_samples_split': [8],\n",
    "        'n_estimators': [12]\n",
    "        }\n",
    "        # Calling the Support Vector Classifier function\n",
    "        RandomForest=RandomForestClassifier()\n",
    "\n",
    "        # Discovering the optimum in the parameter grid\n",
    "        print('[UPDATE] GridSearch initiated....')\n",
    "        RFclassifier = GridSearchCV(RandomForest, param_grid)\n",
    "\n",
    "        # Training the model using the discovered SVC function with the discovered parameters\n",
    "        print('[UPDATE] Training model....')\n",
    "        RFclassifier.fit(X_train,y_train)\n",
    "\n",
    "        print('[UPDATE] Best hyperparameters found in gridsearch: ', RFclassifier.best_params_)\n",
    "\n",
    "        dump(RFclassifier, 'PIPE4_RF.joblib') \n",
    "        print('[UPDATE] Model has been saved!')\n",
    "\n",
    "        # Making Prediction\n",
    "        y_pred=RFclassifier.predict(X_norm)\n",
    "\n",
    "    if crossval == 'yes':\n",
    "        print('[UPDATE] Cross-validating accuracy...')\n",
    "        \n",
    "        # !!! COMMENT CROSS_VAL_SCORE FOR FASTER COMPUTATION !!!\n",
    "        scores = cross_val_score(RFclassifier, X_norm, y, cv=StratifiedKFold(10))\n",
    "        print('------------- Cross validated accuracy ---------------')\n",
    "        print(scores)\n",
    "        print(\"Accuracy: %0.4f (+/- %0.4f)\" % (scores.mean(), scores.std() * 2))\n",
    "        print(' ')\n",
    "        \n",
    "\n",
    "    if getResult == 'yes': # Print results \n",
    "        print('[UPDATE] Printing Results')\n",
    "        print('------------------ Confusion Matrix -------------------')\n",
    "        print(confusion_matrix(y,y_pred))\n",
    "        print(' ')\n",
    "        print('---------------- Classification report ----------------')\n",
    "        print(classification_report(y,y_pred))\n",
    "        print(' ')\n",
    "        print('--------------------- AUC score -----------------------')\n",
    "        print(roc_auc_score(y, y_pred))\n",
    "    elif getResult == 'no':\n",
    "        print('[UPDATE] Results not requested')\n",
    "    else:\n",
    "        print('[UPDATE] !!!THE REQUEST FOR RESULTS WAS INVALID!!!!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load images, feature extraction, and call random forest classifier\n",
    "This code block is what was used to test the the random forest classifier.\n",
    "\n",
    "(Import packages and random forest function before running this)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SAMPLESIZE: 3999\n",
      "[UPDATE] Data has been loaded successfully!\n",
      "[UPDATE] GridSearch initiated....\n",
      "[UPDATE] Training model....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UPDATE] Best hyperparameters found in gridsearch:  {'max_depth': 4, 'min_samples_leaf': 5, 'bootstrap': True, 'n_estimators': 12, 'min_samples_split': 8, 'max_features': 3}\n",
      "[UPDATE] Model has been saved!\n",
      "[UPDATE] Cross-validating accuracy...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/sklearn/model_selection/_split.py:1943: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- Cross validated accuracy ---------------\n",
      "[0.99125    0.98625    0.9925     0.99125    0.9875     0.985\n",
      " 0.98       0.995      0.995      0.98621554]\n",
      "Accuracy: 0.9890 (+/- 0.0091)\n",
      " \n",
      "[UPDATE] Printing Results\n",
      "------------------ Confusion Matrix -------------------\n",
      "[[3986   13]\n",
      " [  43 3956]]\n",
      " \n",
      "---------------- Classification report ----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      1.00      0.99      3999\n",
      "         1.0       1.00      0.99      0.99      3999\n",
      "\n",
      "   micro avg       0.99      0.99      0.99      7998\n",
      "   macro avg       0.99      0.99      0.99      7998\n",
      "weighted avg       0.99      0.99      0.99      7998\n",
      "\n",
      " \n",
      "--------------------- AUC score -----------------------\n",
      "0.9929982495623906\n",
      "----------------- Augmentation type -------------------\n",
      "dark005\n"
     ]
    }
   ],
   "source": [
    "augmentation_type = 'dark005'\n",
    "pipeline = imlib.pip1\n",
    "directory ='darken/' + augmentation_type\n",
    "path = \"/home/sofus/deep/data/Augmented/\"\n",
    "\n",
    "pos = [cv2.cvtColor(cv2.imread(path + directory + \"/Positive/{}_1.jpg\".format(i)), cv2.COLOR_BGR2GRAY) for i in range(10502, 14501)]\n",
    "neg = [cv2.cvtColor(cv2.imread(path + directory + \"/Negative/{}.jpg\".format(i)), cv2.COLOR_BGR2GRAY)  for i in range(10502, 14501)]\n",
    "\n",
    "out_p = [pipeline(img) for img in pos]\n",
    "out_n = [pipeline(img) for img in neg]\n",
    "\n",
    "feat_pos = [imlib.feature_extraction(img, out_p[i]) for i, img in enumerate(pos)]\n",
    "feat_neg = [imlib.feature_extraction(img, out_n[i]) for i, img in enumerate(neg)]\n",
    "\n",
    "SAMPLE_SIZE = len(feat_pos)\n",
    "print('SAMPLESIZE:', len(feat_pos))\n",
    "\n",
    "# Generating the features\n",
    "int_mean_p = [feat_pos[i][0] for i in range(len(feat_pos))]\n",
    "int_mean_n = [feat_neg[i][0] for i in range(len(feat_neg))]\n",
    "int_mean = np.concatenate((int_mean_p, int_mean_n))\n",
    "\n",
    "int_stdev_p = [feat_pos[i][1] for i in range(len(feat_pos))]\n",
    "int_stdev_n = [feat_neg[i][1] for i in range(len(feat_neg))]\n",
    "int_stdev = np.concatenate((int_stdev_p, int_stdev_n))\n",
    "\n",
    "ratio_p = [feat_pos[i][2] for i in range(len(feat_pos))]\n",
    "ratio_n = [feat_neg[i][2] for i in range(len(feat_neg))]\n",
    "ratio = np.concatenate((ratio_p, ratio_n))\n",
    "\n",
    "grad_mean_p = [feat_pos[i][3] for i in range(len(feat_pos))]\n",
    "grad_mean_n = [feat_neg[i][3] for i in range(len(feat_neg))]\n",
    "grad_mean = np.concatenate((grad_mean_p, grad_mean_n))\n",
    "\n",
    "grad_mag_p = [feat_pos[i][4] for i in range(len(feat_pos))]\n",
    "grad_mag_n = [feat_neg[i][4] for i in range(len(feat_neg))]\n",
    "grad_mag = np.concatenate((grad_mag_p, grad_mag_n))\n",
    "\n",
    "grad_angle_p = [feat_pos[i][5] for i in range(len(feat_pos))]\n",
    "grad_angle_n = [feat_neg[i][5] for i in range(len(feat_neg))]\n",
    "grad_angle = np.concatenate((grad_angle_p, grad_angle_n))\n",
    "\n",
    "grad_max_p = [feat_pos[i][6] for i in range(len(feat_pos))]\n",
    "grad_max_n = [feat_neg[i][6] for i in range(len(feat_neg))]\n",
    "grad_max = np.concatenate((grad_max_p, grad_max_n))\n",
    "\n",
    "grad_mag_mean_p = [feat_pos[i][7] for i in range(len(feat_pos))]\n",
    "grad_mag_mean_n = [feat_neg[i][7] for i in range(len(feat_neg))]\n",
    "grad_mag_mean = np.concatenate((grad_mag_mean_p, grad_mag_mean_n))\n",
    "\n",
    "grad_stand_p = [feat_pos[i][8] for i in range(len(feat_pos))]\n",
    "grad_stand_n = [feat_neg[i][8] for i in range(len(feat_neg))]\n",
    "grad_stand = np.concatenate((grad_stand_p, grad_stand_n))\n",
    "\n",
    "mean_int_p = [feat_pos[i][9] for i in range(len(feat_pos))]\n",
    "mean_int_n = [feat_neg[i][9] for i in range(len(feat_neg))]\n",
    "mean_int = np.concatenate((mean_int_p, mean_int_n))\n",
    "\n",
    "stdev_mean_p = [feat_pos[i][10] for i in range(len(feat_pos))]\n",
    "stdev_mean_n = [feat_neg[i][10] for i in range(len(feat_neg))]\n",
    "stdev_mean = np.concatenate((stdev_mean_p, stdev_mean_n))\n",
    "\n",
    "# Generating corresponding labels\n",
    "label_neg = np.array(np.zeros(SAMPLE_SIZE, dtype = int))\n",
    "label_pos = np.array(np.ones(SAMPLE_SIZE, dtype = int))\n",
    "labels = np.concatenate((label_pos, label_neg),0)\n",
    "\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(np.column_stack([int_mean, int_stdev, ratio, grad_mean, grad_mag, grad_angle, grad_max, \n",
    "                                   grad_mag_mean, grad_stand, mean_int, stdev_mean, labels]),  \n",
    "                  \n",
    "                  \n",
    "                  \n",
    "                  columns=['Local IntensMean', 'Local IntensStDev', 'Ratio', 'GradMean', \n",
    "                           'Unique Grad Mag', 'Unique Grad Angle', 'Grad Max', 'Grad Mag Mean', 'Grad Stand',\n",
    "                           'Global intensMean', 'Global Intens Stand', 'label'])\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "# Running the SVM classifier\n",
    "RFclassification(df, getResult = 'yes', crossval='yes' ,testSize = 0.2051, pretrainedModel = 'no')\n",
    "print('----------------- Augmentation type -------------------')\n",
    "print(augmentation_type)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
